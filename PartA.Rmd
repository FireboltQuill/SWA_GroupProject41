
Cover Sheet
========================================================


By including this statement, we, all the students listed in the table
below, declare that:

- We hold a copy of this assignment if the original is lost or damaged.

- We hereby certify that no part of this assignment has been copied from
  any other student's work or from any other source except where due
  acknowledgement is made in the assignment.

- No part of the assignment has been written for us by any other person
  except where collaboration has been authorised by the unit coordinator.

- We are aware that this work may be reproduced and submitted to plagiarism
  detection software programs for the purpose of detecting possible
  plagiarism; this software may retain a copy on its database for future
  plagiarism checking.

- We hereby certify that no part of this assignment or product has been
  submitted by any of us in another (previous or current) assessment, except
  where appropriately referenced, and with prior permission from the unit
  coordinator for this unit.

- We hereby certify that we have read and understand what the University
  considers to be academic misconduct, and that we are aware of the
  penalties that may be imposed for academic misconduct.

Name               | Student Number | Contribution (%)
-------------------|----------------|-----------------
                   |                |
                   |                |
                   |                |
                   |                |

<div style="page-break-before:always;"></div>

8.1 Analysis of Twitter language about the Public Figure
In this section, we want to examine the language used in tweets. Use the rtweet package to download tweets.

1.       Use the search_tweets function from the rtweet library to search for 1000 tweets about the person you selected. Save these tweets as "tweets".

```{r}
library("ROAuth")
library("tm")
library("wordcloud")
library("rtweet")
library("twitteR")
library("wordcloud2")

key="3g0mNQkwVxe0JKiRfSyyS0rvu"
secret="Wu38XdVVJFPWpqWVBQDwyl2Reqhmg8XhDWjTJl3XwOqNlwYEcx"
access_token="243587433-BPMCMRHSyb3pSJS3raa0w9qPCU3RAnB3aPZtjVEM"
access_secret="g8iN8UChw7jAnybFKfMxPWiWiS8hZw1lVeKzmipnnu3zR"
app="WSU300958"
setup_twitter_oauth(key,secret,access_token,access_secret)
## tweets=search_tweets(q="J.K.Rowling",n=1000,lang="en",include_rts = FALSE)
## tweets$text[1:10]
## save_as_csv(tweets,"SWAProject.csv")

tweets=read.csv("SWAProject.csv")
```

2.      Construct a document-term matrix or term-document matrix using TFIDF weighting.

```{r echo=FALSE}
corpus=Corpus(VectorSource(tweets$text))
corpus = tm_map(corpus, function(x) iconv(x, to = 'UTF8', sub = 'byte'))
corpus = tm_map(corpus, function(x) iconv(x, to = 'ASCII', sub = ' '))
corpus = tm_map(corpus,removeNumbers)

corpus = tm_map(corpus,removePunctuation)
corpus = tm_map(corpus,stripWhitespace)
corpus = tm_map(corpus, tolower)

corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, removeWords,c(stopwords(),"jk","https", "t.co","rowl","jkrowl","will","like","just","doe","far","quot"))

dtm = DocumentTermMatrix(corpus)
tweet.wdtm = weightTfIdf(dtm)
tweet.matrix = as.matrix(tweet.wdtm)

```

3.      Construct a word cloud of the words in your document term matrix. Make sure you removed all the words non-informative by updating your stop list.
```{r}
freqs=colSums(tweet.matrix)

wordcloud(names(freqs),freqs,scale=c(2,0.5),random.order = FALSE,use.r.layout=FALSE,
                  colors=brewer.pal(8, "Dark2"),min.freq = 3)

data = data.frame(names(freqs), freqs)
wordcloud2(data, size = 0.3, shape = "circle")
```

4.      Sum the frequencies of each terms in all documents to obtain a vector of term frequencies summed over all tweets.
```{r}
## freqs=colSums(tweet.matrix)
## ^^ Calculated in question 3

freqs

```

5.      Compute the proportion of each term in the tweets from the vector of term frequencies. Visualize the top 20 words and their proportion by using a bar plot.
```{r}
id=order(freqs,decreasing = TRUE)[1:20]

topWords=colnames(tweet.matrix)[id]

N = length(freqs)
words.proportion = freqs/N

barplot(words.proportion[id], col=heat.colors(20),las=2)

```

7.      Create a dendrogram of the words in your document term matrix. You do not need to visualize all words in your dendrogram, set up appropriate boundaries to improve the visualization.

                    i.     Try simple and complete linkage clustering.
         
```{r}
id2 = order(freqs, decreasing = TRUE)[1:50]
                    topWords.clus = colnames(tweet.matrix)[id2]
 D = dist(freqs[id2])
                    h.complete = hclust(D)
                    plot(h.complete)

                    h.single = hclust(D, method="single")
                    plot(h.single)

```

                   
                   ```
                    ii.    Which one do you think performed better?
                    

What do these words tell us about the Person? Comment on what people are saying about this person? 



8.2 Clustering the Users Who Posted Tweets About the Public Figure
We want to categorize (cluster) the users of the tweets about the Public Figure based on the descriptions provided in their Twitter account to figure out what kind of users are tweeting about them. Descriptions in the users' Twitter profiles give a short piece of information about the Twitter handle. To cluster users, built a document term matrix by using the user descriptions of the tweets you downloaded at section 1.

1.     Compute the most appropriate number of clusters using the elbow method. Make sure an appropriate metric is used.

2.    Cluster the users and visualize the clusters in two dimensional vector space.

3.    List the top 10 words associated with each user cluster and manually determine the type of user profiles for each cluster (e.g. journalist, organisation, personal).

4.    Comment on your findings.

```{r}

```

8.3 Retweet Analysis of the User Clusters
We want to examine if the number of retweeted tweets is independent of which user cluster posted the tweet.

1.       Find the tweets of the users at each cluster at your tweets file and examine how many of them are retweeted.

2.      Construct a 2Ã—M table where M is the number of user clusters you found at Section 2. Each row (2 rows in total) should represent the total number of retweeted tweets and non-retweeted tweets in each cluster.

3.      Is retweeting independent of user groups? Perform an appropriate test to answer this question.

4.      Interpret your results in context.

By combining all your findings, what can we say about the person's image on Twitter? Draw a conclusion from your report.

The person wants the above three parts of analysis to be written up in a professional report. Each part should have its own section of the report and all questions should have thoughtful answers. Include only the relevant piece of code along with its output in the body of your assignment. More detailed code should be in the Appendix part of the assignment.
